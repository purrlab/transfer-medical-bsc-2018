{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"Data\":'KaggleDR',\n",
    "        \"data_name\":None,\n",
    "        \"style\":None,\n",
    "        \"model\": \"KaggleDR\",\n",
    "        \"file_path\":r\"C:\\KaggleDR\",\n",
    "        \"pickle_path\":r\"C:\\pickles\\KaggleDR\",\n",
    "        \"model_path\":{\"Nat\":r\"C:\\models\\Epochs_50_Nat.json\",\"KaggleDR\":r\"C:\\models\\Epochs_50_kaggleDR.json\",\"Chest\":r\"C:\\models\\Epochs_50_Chest.json\", \"CatDog\":r\"C:\\models\\Epochs_40_CatDog.json\" },\n",
    "        \"RandomSeed\":2,\n",
    "        \"doc_path\":r\"C:\\Users\\Flori\\Documents\\GitHub\\t\",\n",
    "        'img_size_x':224,\n",
    "        'img_size_y':224,\n",
    "        'norm':False,\n",
    "        'color':True, \n",
    "        'pretrain':None, \n",
    "        \"equal_data\":False, \n",
    "        \"shuffle\":True, \n",
    "        \"epochs\":50, \n",
    "        \"val_size\":5000,\n",
    "        \"test_size\":5000, \n",
    "        \"Batch_size\":32,\n",
    "        \"stop\":'yes'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"Data\":'Nat',\n",
    "        \"style\":'none',\n",
    "        \"model\":'Nat',\n",
    "        'file_path':r\"C:\\natural_images\",\n",
    "        'pickle_path':r\"C:\\pickles\\Nat\",\n",
    "        \"model_path\":{\"Nat\":r\"C:\\models\\Epochs_50_Nat.json\",\"KaggleDR\":r\"C:\\models\\Epochs_50_kaggleDR.json\",\"Chest\":r\"C:\\models\\Epochs_50_Chest.json\", \"CatDog\":r\"C:\\models\\Epochs_40_CatDog.json\" },\n",
    "        \"RandomSeed\":2,\n",
    "        \"doc_path\":r\"C:\\Users\\Flori\\Documents\\GitHub\\t\",\n",
    "        'img_size_x':224,\n",
    "        'img_size_y':224,\n",
    "        'norm':False,\n",
    "        'color':True, \n",
    "        'pretrain':None, \n",
    "        \"equal_data\":False, \n",
    "        \"shuffle\":True, \n",
    "        \"epochs\":1, \n",
    "        \"val_size\":500,\n",
    "        \"test_size\":1000, \n",
    "        \"Batch_size\":32,\n",
    "        \"stop\":'yes'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from AADatasets import *\n",
    "from AAPreTrain import *\n",
    "from AATransferLearn import *\n",
    "from AAlogic import *\n",
    "from LabnotesDoc import *\n",
    "\n",
    "\n",
    "\n",
    "config_desktop()\n",
    "\n",
    "\n",
    "x_test,y_test,x,y = val_split(x,y, params[\"test_size\"])\n",
    "x_val,y_val,x,y = val_split(x,y, params[\"val_size\"])\n",
    "\n",
    "model = make_model(x, y, params)\n",
    "# weights = determen_weights(y)\n",
    "H, score, model = train_model(model,x,y,x_val,y_val,x_test,y_test, params)\n",
    "\n",
    "# if params[\"style\"] == 'FT':\n",
    "#     model = make_model(x, y, params)\n",
    "#     weights = determen_weights(y)\n",
    "#     H, score, model = train_model(model,x,y,x_val,y_val,x_test,y_test, params, weights)\n",
    "#     predictions = get_feature_vector(model, x, layer = 'fc2')\n",
    "#     predictions_test = get_feature_vector(model, x_test, layer = 'fc2')\n",
    "#     score = auc_svm(predictions,y,predictions_test,y_test, plot = False)\n",
    "#     results = {'score':score,\"acc_epoch\":H.history['acc'],\"val_acc_epoch\":H.history['val_acc'],\"loss_epoch\":H.history['loss'],\"vall_loss_epoch\":H.history['val_loss']}\n",
    "\n",
    "# elif params[\"style\"] =='SVM':\n",
    "#     predictions = x.flatten().reshape(len(x), 224*224)\n",
    "#     predictions_test = x_test.flatten().reshape(len(x_test), 224*224)\n",
    "#     score = auc_svm(predictions,y,predictions_test,y_test, plot = False)\n",
    "#     results = {'score':score,'data_name':params[\"data_name\"],'method':params[\"model\"],'style':params[\"style\"]}\n",
    "#     H=None\n",
    "path = r'C:\\models\\NEW'\n",
    "#save model to JSON\n",
    "model_json = model.to_json()\n",
    "# with open(f\"{params['model_path']}{params['epochs']}_{params['Data']}.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "with open(f\"{path}ModelChange_{params['model']}.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "# model.save_weights(f\"{params['model_path']}{params['epochs']}_{params['Data']}_Weights.h5\")\n",
    "# print(\"Saved model to disk\")\n",
    "model.save_weights(f\"{path}ModelChange_{params['model']}_Weights.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "results = {'score':score,\"acc_epoch\":H.history['acc'],\"val_acc_epoch\":H.history['val_acc'],\"loss_epoch\":H.history['loss'],\"vall_loss_epoch\":H.history['val_loss']}\n",
    "\n",
    "doc(params,results,H,params[\"doc_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading(size,i,start, name):\n",
    "    stop = time.time()\n",
    "    part = int(((i+1)/size)*20)\n",
    "    loading_bar = part*'-'+(20-part)*' '\n",
    "    print(f\"{name}: {i+1}/{size}: [{loading_bar[0:10]}{part*5}%{loading_bar[10:20]}] elapsed time: {int(stop-start)}\",end='\\r')\n",
    "\n",
    "def more_data(x,y,r):\n",
    "    x_new = x\n",
    "    y_new = y\n",
    "    start = time.time()\n",
    "    for i in range(0,r):\n",
    "        loading(r,i,start, \"Data generator\")\n",
    "        datagen =  tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=360, fill_mode = \"nearest\")\n",
    "        img=datagen.random_transform(x[i])\n",
    "        y_new = np.concatenate((y_new, np.array(y[i]).reshape(1,y.shape[1])))\n",
    "        x_new = np.concatenate((x_new, np.array(img).reshape(1,img.shape[0], img.shape[1],img.shape[2])))\n",
    "    print(\"\\n\")\n",
    "    return x_new,y_new\n",
    "\n",
    "def equal_data(x,y):\n",
    "    d = count_classes(y)\n",
    "    l = list()\n",
    "    for key in d.keys():\n",
    "        l.append(d[key])\n",
    "    limit = max(l)\n",
    "\n",
    "    zip_melanoom = zip(x,y)\n",
    "    zippy = list(zip_melanoom)\n",
    "    random.shuffle(zippy)\n",
    "    x,y = zip(*zippy)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    bad = list()\n",
    "    datagen =  tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=360, fill_mode = \"nearest\")\n",
    "\n",
    "    x_new = x\n",
    "    y_new = y\n",
    "    start = time.time()\n",
    "    for i in range(0,len(y)):\n",
    "        loading(len(y),i,start, \"Data generator\")\n",
    "        \n",
    "        if not d[list(y[i]).index(1)] < limit:\n",
    "            bad.append(list(y[i]))\n",
    "            continue\n",
    "        if list(y[i]).index(1) in bad:\n",
    "            continue\n",
    "        img=datagen.random_transform(x[i])\n",
    "        y_new = np.concatenate((y_new, np.array(y[i]).reshape(1,y.shape[1])))\n",
    "        x_new = np.concatenate((x_new, np.array(img).reshape(1,img.shape[0], img.shape[1],img.shape[2])))\n",
    "        d = count_classes(y_new)\n",
    "        if not d[list(y[i]).index(1)] < limit:\n",
    "            bad.append(list(y[i]).index(1))\n",
    "    print(\"\\n\")\n",
    "    return x_new,y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to import pickle\n",
      "succeed to import pickle\n",
      " unzip\n"
     ]
    }
   ],
   "source": [
    "x,y = get_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_data_min(x,y):\n",
    "    d = count_classes(y)\n",
    "    if type(d) == dict:\n",
    "        l = list()\n",
    "        for key in d.keys():\n",
    "            l.append(d[key])\n",
    "        limit = min(l)\n",
    "    else:\n",
    "        limit = min(d)\n",
    "\n",
    "    back_to_num = list()\n",
    "    for i in list(y):\n",
    "        back_to_num.append(list(i).index(1))\n",
    "    \n",
    "    X = list()\n",
    "    Y = list()\n",
    "    d = dict()\n",
    "    for n,img in zip(back_to_num,zip(x,y)):\n",
    "        if n in d:\n",
    "            if d[n] >= limit:\n",
    "                continue\n",
    "            d[n] += 1\n",
    "            X.append(img[0])\n",
    "            Y.append(img[1])\n",
    "        else:\n",
    "            d[n] = 1\n",
    "            X.append(img[0])\n",
    "            Y.append(img[1])\n",
    "    return np.array(X),np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2,y2 = equal_data_min(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(x,y):\n",
    "    datagen =  tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=360, fill_mode = \"nearest\")\n",
    "    start = time.time()\n",
    "    x_new = x[1000:]\n",
    "    y_new = y[1000:]\n",
    "    for i in range(0,len(y)):\n",
    "        if list(y[i]).index(1) == 0:\n",
    "            continue\n",
    "        loading(len(y),i,start, \"Data generator\")\n",
    "        img=datagen.random_transform(x[i])\n",
    "        y_new = np.concatenate((y_new, np.array(y[i]).reshape(1,y.shape[1])))\n",
    "        x_new = np.concatenate((x_new, np.array(img).reshape(1,img.shape[0], img.shape[1],img.shape[2])))\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    return x_new,y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generator: 3540/3540: [----------100%----------] elapsed time: 1532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x3,y3 = data_gen(x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =0 \n",
    "x3= 0\n",
    "x2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = np.concatenate((y,y3))\n",
    "x_new = np.concatenate((x,x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_split(x,y, val_size):\n",
    "    return x[-val_size:] ,y[-val_size:] ,x[:-val_size] ,y[:-val_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test,x,y = val_split(x_new,y_new, params[\"test_size\"])\n",
    "x_val,y_val,x,y = val_split(x,y, params[\"val_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 22416, 2: 4591, 4: 624, 1: 2107, 3: 760}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_classes(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.6534562211981567,\n",
       " 1: 9.75936,\n",
       " 2: 6.116726835138388,\n",
       " 3: 15.04588061174149,\n",
       " 4: 15.925848563968668}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\models\\Epochs_50_kaggleDR.json\n",
      "Loaded model from disk\n",
      "MODEL SUMMARY:\n",
      "<tensorflow.python.keras._impl.keras.engine.topology.InputLayer object at 0x00000169E7FEAE10> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000168917C5128> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169E7FEAC18> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000169E7FEAA90> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169E7FEA940> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169E7FEA4E0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000169487B4128> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169487B41D0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169487B4320> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169487B4470> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000169487B45C0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169487B4668> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169487B47B8> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169487B4908> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000169487B4A58> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169487B4B00> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169487B4C50> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000169487B4DA0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000169487B4EF0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Flatten object at 0x00000169487B4F98> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000169487BB048> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000169487BB160> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000169487BB278> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000168917C5048> True\n",
      "END OF SUMMARY\n"
     ]
    }
   ],
   "source": [
    "model = make_model(x, y, params)\n",
    "weights = determen_weights(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30498 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 636s 21ms/step - loss: 5.3279 - acc: 0.6468 - val_loss: 1.4136 - val_acc: 0.5588\n",
      "\n",
      "Epoch 2/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 632s 21ms/step - loss: 5.0717 - acc: 0.6496 - val_loss: 1.3407 - val_acc: 0.6060\n",
      "\n",
      "Epoch 3/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 632s 21ms/step - loss: 4.8495 - acc: 0.7140 - val_loss: 1.2709 - val_acc: 0.6588\n",
      "\n",
      "Epoch 4/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 4.6391 - acc: 0.7592 - val_loss: 1.2001 - val_acc: 0.7160\n",
      "\n",
      "Epoch 5/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 4.4354 - acc: 0.7886 - val_loss: 1.1537 - val_acc: 0.7032\n",
      "\n",
      "Epoch 6/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 4.2433 - acc: 0.8070 - val_loss: 1.0973 - val_acc: 0.7312\n",
      "\n",
      "Epoch 7/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 4.0604 - acc: 0.8277 - val_loss: 1.2668 - val_acc: 0.4488\n",
      "\n",
      "Epoch 8/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 631s 21ms/step - loss: 3.9034 - acc: 0.8201 - val_loss: 1.0198 - val_acc: 0.7194\n",
      "\n",
      "Epoch 9/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 3.7530 - acc: 0.8373 - val_loss: 0.9558 - val_acc: 0.7646\n",
      "\n",
      "Epoch 10/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 3.6074 - acc: 0.8406 - val_loss: 0.9652 - val_acc: 0.7226\n",
      "\n",
      "Epoch 11/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 3.4475 - acc: 0.8474 - val_loss: 0.8992 - val_acc: 0.7590\n",
      "\n",
      "Epoch 12/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 3.3106 - acc: 0.8503 - val_loss: 0.8460 - val_acc: 0.7756\n",
      "\n",
      "Epoch 13/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 3.1359 - acc: 0.8637 - val_loss: 0.9058 - val_acc: 0.7202\n",
      "\n",
      "Epoch 14/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 3.0612 - acc: 0.8578 - val_loss: 0.8919 - val_acc: 0.7372\n",
      "\n",
      "Epoch 15/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 2.9700 - acc: 0.8564 - val_loss: 0.8455 - val_acc: 0.7416\n",
      "\n",
      "Epoch 16/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 2.8475 - acc: 0.8640 - val_loss: 0.8143 - val_acc: 0.7560\n",
      "\n",
      "Epoch 17/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 2.7686 - acc: 0.8652 - val_loss: 0.8110 - val_acc: 0.7480\n",
      "\n",
      "Epoch 18/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 2.6848 - acc: 0.8672 - val_loss: 0.8979 - val_acc: 0.6998\n",
      "\n",
      "Epoch 19/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 2.5396 - acc: 0.8806 - val_loss: 0.7851 - val_acc: 0.7600\n",
      "\n",
      "Epoch 20/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 630s 21ms/step - loss: 2.4020 - acc: 0.8956 - val_loss: 0.8113 - val_acc: 0.7410\n",
      "\n",
      "Epoch 21/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 2.3700 - acc: 0.8910 - val_loss: 0.8287 - val_acc: 0.7380\n",
      "\n",
      "Epoch 22/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 2.3238 - acc: 0.8899 - val_loss: 0.7837 - val_acc: 0.7524\n",
      "\n",
      "Epoch 23/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 2.2843 - acc: 0.8885 - val_loss: 0.7850 - val_acc: 0.7582\n",
      "\n",
      "Epoch 24/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 631s 21ms/step - loss: 2.2130 - acc: 0.8954 - val_loss: 0.9107 - val_acc: 0.7066\n",
      "\n",
      "Epoch 25/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 2.1684 - acc: 0.8966 - val_loss: 0.8655 - val_acc: 0.7272\n",
      "\n",
      "Epoch 26/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 2.2026 - acc: 0.8844 - val_loss: 0.8683 - val_acc: 0.7400\n",
      "\n",
      "Epoch 27/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 2.1629 - acc: 0.8908 - val_loss: 0.8406 - val_acc: 0.7326\n",
      "\n",
      "Epoch 28/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 632s 21ms/step - loss: 2.0996 - acc: 0.8957 - val_loss: 0.8418 - val_acc: 0.7310\n",
      "\n",
      "Epoch 29/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 632s 21ms/step - loss: 2.0524 - acc: 0.8977 - val_loss: 0.7820 - val_acc: 0.7610\n",
      "\n",
      "Epoch 30/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 1.9529 - acc: 0.9071 - val_loss: 0.8205 - val_acc: 0.7494\n",
      "\n",
      "Epoch 31/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 629s 21ms/step - loss: 1.9335 - acc: 0.9075 - val_loss: 0.8118 - val_acc: 0.7526\n",
      "\n",
      "Epoch 32/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 631s 21ms/step - loss: 1.8821 - acc: 0.9109 - val_loss: 0.8864 - val_acc: 0.7276\n",
      "\n",
      "Epoch 33/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 1.8519 - acc: 0.9118 - val_loss: 0.8652 - val_acc: 0.7378\n",
      "\n",
      "Epoch 34/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 1.9661 - acc: 0.8997 - val_loss: 0.8285 - val_acc: 0.7514\n",
      "\n",
      "Epoch 35/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 1.8851 - acc: 0.9049 - val_loss: 0.9092 - val_acc: 0.7182\n",
      "\n",
      "Epoch 36/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 633s 21ms/step - loss: 1.8128 - acc: 0.9116 - val_loss: 0.8690 - val_acc: 0.7430\n",
      "\n",
      "Epoch 37/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 632s 21ms/step - loss: 1.8042 - acc: 0.9110 - val_loss: 0.8388 - val_acc: 0.7566\n",
      "\n",
      "Epoch 38/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 631s 21ms/step - loss: 1.7652 - acc: 0.9151 - val_loss: 0.8418 - val_acc: 0.7536\n",
      "\n",
      "Epoch 39/50\n",
      "30498/30498 [==============================]30498/30498 [==============================] - 628s 21ms/step - loss: 1.7418 - acc: 0.9160 - val_loss: 0.8565 - val_acc: 0.7488\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-27d244774e37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\transfer-medical-bsc-2018\\AAPreTrain.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, x_train, y_train, x_val, y_val, x_test, y_test, params, weights_dict)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mTrains\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtrains\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mearly\u001b[0m \u001b[0mstopping\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpossibility\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0mBest\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0monly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mInput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mOutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m## Extract some params to make it more readable ##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\flori\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    349\u001b[0m     return _average_binary_score(\n\u001b[0;32m    350\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\flori\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         score[c] = binary_metric(y_true_c, y_score_c,\n\u001b[1;32m--> 120\u001b[1;33m                                  sample_weight=score_weight)\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;31m# Average the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\flori\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    320\u001b[0m                              \"is not defined in that case.\")\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "H, score, model = train_model(model,x,y,x_val,y_val,x_test,y_test, params,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"C:\\models\\Epochs50_kaggleDR.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "## Serialize weights to HDF5 ##\n",
    "model.save_weights(\"C:\\models\\Epochs50_kaggleDR_Weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = y_proba.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "back_to_num = list()\n",
    "list_classes = list(y)\n",
    "for i in list_classes:\n",
    "    back_to_num.append(list(i).index(1))\n",
    "\n",
    "y_pred = []\n",
    "for c in y_proba:\n",
    "    y_pred.append(list(c).index(max(c)))\n",
    "    \n",
    "cnf_matrix = confusion_matrix(back_to_num, y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   3, 551,   0,   9,  10],\n",
       "       [  2,  10,   0,   5,   1,   0, 733,   4],\n",
       "       [  5,  14,   0,   3,  14,   4, 597,  55],\n",
       "       [  3,  17,   0,   4,  12,   5, 127, 390],\n",
       "       [  1, 605,   0,  10,   8,   5,  22,  20],\n",
       "       [743,   0,   0,   0,   3,   0,   1,   0],\n",
       "       [  0,   8,   0, 603,   1,   0,   7,   0],\n",
       "       [  1, 763,   0,   0,   0,   0,  17,   3]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   3, 551,   0,   9,  10],\n",
       "       [  2,  10,   0,   5,   1,   0, 733,   4],\n",
       "       [  5,  14,   0,   3,  14,   4, 597,  55],\n",
       "       [  3,  17,   0,   4,  12,   5, 127, 390],\n",
       "       [  1, 605,   0,  10,   8,   5,  22,  20],\n",
       "       [743,   0,   0,   0,   3,   0,   1,   0],\n",
       "       [  0,   8,   0, 603,   1,   0,   7,   0],\n",
       "       [  1, 763,   0,   0,   0,   0,  17,   3]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "score = roc_auc_score(y_test, model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43843318153651234"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
