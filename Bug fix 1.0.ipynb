{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from AADatasets import *\n",
    "from AAPreTrain import *\n",
    "from AATransferLearn import *\n",
    "from AAlogic import *\n",
    "from LabnotesDoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_target(params):\n",
    "    x,y = get_data(params)\n",
    "    # x,y = keep_class(x,y,[0,1,2])\n",
    "    # x,y = equal_data_min(x,y)\n",
    "\n",
    "    x_test,y_test,x,y = val_split(x,y, params[\"test_size\"])\n",
    "    x_val,y_val,x,y = val_split(x,y, params[\"val_size\"])\n",
    "    \n",
    "    # for method in m:\n",
    "    config_desktop()\n",
    "#     gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.45)\n",
    "\n",
    "    model = make_model(x, y, params)\n",
    "\n",
    "    if params[\"style\"] == 'FT':\n",
    "        weights = determen_weights(y)\n",
    "        H, score, model = train_model(model,x,y,x_val,y_val,x_test,y_test, params[\"epochs\"], params[\"Batch_size\"])\n",
    "        predictions = get_feature_vector(model, x, layer = 'fc2')\n",
    "        predictions_test = get_feature_vector(model, x_test, layer = 'fc2')\n",
    "        score = auc_svm(predictions,y,predictions_test,y_test, plot = False)\n",
    "        results = {'score':score,\"acc_epoch\":H.history['acc'],\"val_acc_epoch\":H.history['val_acc'],\"loss_epoch\":H.history['loss'],\"vall_loss_epoch\":H.history['val_loss']}\n",
    "\n",
    "    elif params[\"style\"] =='SVM':\n",
    "        predictions = get_feature_vector(model, x, layer = 'fc2')\n",
    "        predictions_test = get_feature_vector(model, x_test, layer = 'fc2')\n",
    "        score = auc_svm(predictions,y,predictions_test,y_test, plot = False)\n",
    "        results = {'score':score,'data_name':params[\"data_name\"],'method':params[\"model\"],'style':params[\"style\"]}\n",
    "        H=None\n",
    "\n",
    "    doc(params,results,H,params[\"doc_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"Data\":'Breast',\n",
    "                \"data_name\":None,\n",
    "                \"style\":'FT',\n",
    "                \"model\":\"imagenet\",\n",
    "                \"file_path\":r\"C:\\breast-ultrasound-image\",\n",
    "                \"pickle_path\":r\"C:\\pickles\\Breast\",\n",
    "                \"model_path\":{\"KaggleDR\":r\"C:\\models\\Epochs_50_kaggleDR.json\",\"Chest\":r\"C:\\models\\Epochs_50_Chest.json\", \"CatDog\":r\"C:\\models\\Epochs_40_CatDog.json\" },\n",
    "                \"RandomSeed\":2,\n",
    "                \"doc_path\":r\"C:\\Users\\Flori\\Documents\\GitHub\\t\",\n",
    "                'img_size_x':224,\n",
    "                'img_size_y':224,\n",
    "                'norm':False,\n",
    "                'color':True, \n",
    "                'pretrain':None, \n",
    "                \"equal_data\":False, \n",
    "                \"shuffle\":True, \n",
    "                \"epochs\":1 , \n",
    "                \"val_size\":25,\n",
    "                \"test_size\":50, \n",
    "                \"Batch_size\":4\n",
    "                }\n",
    "params = {\"Data\":'Blood',\n",
    "        \"data_name\":None,\n",
    "        \"style\":\"FT\",\n",
    "        \"model\":\"imagenet\",\n",
    "        \"file_path\":r\"C:\\blood-cells\",\n",
    "        \"pickle_path\":r\"C:\\pickles\\Blood\",\n",
    "        \"model_path\":{\"KaggleDR\":r\"C:\\models\\Epochs_50_kaggleDR.json\",\"Chest\":r\"C:\\models\\Epochs_50_Chest.json\", \"CatDog\":r\"C:\\models\\Epochs_40_CatDog.json\" },\n",
    "        \"RandomSeed\":2,\n",
    "        \"doc_path\":r\"C:\\Users\\Flori\\Documents\\GitHub\\t\",\n",
    "        'img_size_x':224,\n",
    "        'img_size_y':224,\n",
    "        'norm':False,\n",
    "        'color':True, \n",
    "        'pretrain':None, \n",
    "        \"equal_data\":False, \n",
    "        \"shuffle\":True, \n",
    "        \"epochs\":50 , \n",
    "        \"val_size\":300,\n",
    "        \"test_size\":500, \n",
    "        \"Batch_size\":32\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to import pickle\n",
      "succeed to import pickle\n",
      " unzip\n",
      "MODEL SUMMARY:\n",
      "<tensorflow.python.keras._impl.keras.engine.topology.InputLayer object at 0x00000269C327BD68> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000269A10B9320> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x000002699FACD860> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000269C4EE7208> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A0C63D080> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A0C637240> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x0000026A0C6425C0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A0C653CF8> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A0C647278> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A0C660710> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x0000026A0C665EF0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A0C678128> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A0C67F320> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A0C68B080> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x0000026A1BA20278> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A1BA29BA8> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A05665780> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x0000026A05698518> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x0000026A0B58C080> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Flatten object at 0x0000026A0B5A7748> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x0000026A0B5A7A20> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x0000026A12599550> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x0000026A184AB6A0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x0000026A184ABF28> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x0000026A1B9A7898> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x0000026A9E45C5F8> True\n",
      "END OF SUMMARY\n",
      "Train on 11715 samples, validate on 300 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "from AATransferLearn import *\n",
    "run_target(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to import pickle\n",
      "succeed to import pickle\n",
      " unzip\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn import datasets, svm, metrics\n",
    "import os\n",
    "import random\n",
    "import pandas\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def loading(size,i,start, name):\n",
    "    stop = time.time()\n",
    "    part = int(((i+1)/size)*20)\n",
    "    loading_bar = part*'-'+(20-part)*' '\n",
    "    print(f\"{name}: {i+1}/{size}: [{loading_bar[0:10]}{part*5}%{loading_bar[10:20]}] elapsed time: {int(stop-start)}\",end='\\r')\n",
    "\n",
    "def import_dogcat(path, img_size_x,img_size_y, norm, color):\n",
    "    #DIR = r\"C:\\Users\\Floris\\Documents\\Python scripts\\PetImages\"\n",
    "    try: \n",
    "        cat = list(os.listdir(path))\n",
    "        print('Directory found')\n",
    "    except:\n",
    "        print('Directory not Found')\n",
    "\n",
    "\n",
    "    training_data = list()\n",
    "    training_class = list()\n",
    "    \n",
    "    for category in cat:\n",
    "        class_num = cat.index(category)\n",
    "        path2 = os.path.join(path, category)\n",
    "        start = time.time()\n",
    "        i = 0\n",
    "        size = len(list(os.listdir(path2)))\n",
    "        for img in os.listdir(path2):\n",
    "            try:\n",
    "                if color:\n",
    "                    D = 3\n",
    "                    img_array = cv2.imread(os.path.join(path2,img), cv2.IMREAD_COLOR)\n",
    "                    new_array = cv2.resize(img_array,(img_size_x, img_size_y))\n",
    "                    \n",
    "                else:\n",
    "                    D = 1\n",
    "                    img_array = cv2.imread(os.path.join(path2,img), cv2.IMREAD_GRAYSCALE)\n",
    "                    new_array = cv2.resize(img_array,(img_size_x, img_size_y))\n",
    "                training_data.append(new_array)\n",
    "                if class_num == 0:\n",
    "                    training_class.append([1,0])\n",
    "                elif class_num == 1:\n",
    "                    training_class.append([0,1])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            loading(size,i,start, \"Cat_Dog data import\")\n",
    "            i+=1\n",
    "        print(\"\\n\")\n",
    "\n",
    "    zip_list = list(zip(training_data,training_class))\n",
    "#     random.shuffle(zip_list)\n",
    "    training_data,training_class = zip(*zip_list)\n",
    "    x = np.array(training_data).reshape(-1,img_size_x, img_size_y,D)\n",
    "    y = np.array(training_class).reshape(-1,len(cat))\n",
    "\n",
    "    if type(norm) != bool:\n",
    "        print(\"please enter 'boolean' for norm(alization)\")\n",
    "\n",
    "    if norm:\n",
    "        x = x/ 255.0\n",
    "\n",
    "    print(f\"This Dog_Cat dataset contains the following: \\nTotal length Dataset = {len(x)} \")\n",
    "    return x, y\n",
    "\n",
    "\n",
    "random.seed(2)\n",
    "\n",
    "print(\"Try to import pickle\")\n",
    "if params[\"Data\"] == 'ISIC':\n",
    "    zippy = list(pickle.load(open( f\"{params['pickle_path']}{params['data_name']}.p\", \"rb\" )))\n",
    "else:\n",
    "    try:\n",
    "        zippy = list(pickle.load(open( f\"{params['pickle_path']}.p\", \"rb\" )))\n",
    "    except:\n",
    "        zippy = list(pickle.load(open( f\"{params['pickle_path']}_part1.p\", \"rb\" )))\n",
    "        zippy2 = list(pickle.load(open( f\"{params['pickle_path']}_part2.p\", \"rb\" )))\n",
    "        zippy.extend(zippy2)\n",
    "print(\"succeed to import pickle\")\n",
    "\n",
    "print(\" unzip\")\n",
    "random.shuffle(zippy)\n",
    "x,y = zip(*zippy)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "# x,y = import_dogcat(params['file_path'], params['img_size_x'],params['img_size_y'], norm = params[\"norm\"], color = params[\"color\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3109, 3: 3171, 0: 3133, 2: 3102}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_classes(Y):\n",
    "    '''\n",
    "    Counts classes, no matter wich type of class notation it is, array of 1 and 0 or interger.\n",
    "    input: class list\n",
    "    output: class dict, {class:count}\n",
    "    '''\n",
    "    ## checks if they are intergers ##\n",
    "    \n",
    "    back_to_num = list()\n",
    "    list_classes = list(Y)\n",
    "    for i in list_classes:\n",
    "        back_to_num.append(list(i).index(1))\n",
    "        \n",
    "    d = dict()\n",
    "    for n in back_to_num:\n",
    "        if n in d:\n",
    "            d[n] += 1\n",
    "        else:\n",
    "            d[n] = 1\n",
    "    return d\n",
    "\n",
    "count_classes(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_split(x,y, val_size):\n",
    "    return x[:val_size] ,y[:val_size] ,x[val_size:] ,y[val_size:]\n",
    "\n",
    "x_test,y_test,x,y = val_split(x,y, params[\"test_size\"])\n",
    "x_val,y_val,x,y = val_split(x,y, params[\"val_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_classes(y_val)\n",
    "count_classes(y)\n",
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to import pickle\n",
      "succeed to import pickle\n",
      " unzip\n",
      "MODEL SUMMARY:\n",
      "<tensorflow.python.keras._impl.keras.engine.topology.InputLayer object at 0x00000115C19DE3C8> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115C1977630> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x000001159C56E8D0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000115C1977B38> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115C1977A58> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115C19A9400> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000115C5E7F668> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115C5E7FFD0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115D7A4E940> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115D7A846D8> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000115D7A99358> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115D804C198> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115D8068710> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115D809DE80> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000115D809DC88> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115D80CF6D8> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115DC4934E0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.convolutional.Conv2D object at 0x00000115DC4C7DA0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.pooling.MaxPooling2D object at 0x00000115DC4C7F98> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Flatten object at 0x00000115DC4F74A8> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000115DC4F7860> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000115DC52D2B0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000115DC4F7DA0> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000115E46DEB38> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000115E4702438> True\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x00000115E47209B0> True\n",
      "END OF SUMMARY\n",
      "Train on 175 samples, validate on 25 samples\n",
      "Epoch 1/1\n",
      "175/175 [==============================]175/175 [==============================] - 32s 183ms/step - loss: 0.6752 - acc: 0.6000 - val_loss: 0.7019 - val_acc: 0.5200\n",
      "\n",
      " AUC of model =  0.5\n"
     ]
    }
   ],
   "source": [
    "x,y = get_data(params)\n",
    "x_test,y_test,x,y = val_split(x,y, params[\"test_size\"])\n",
    "x_val,y_val,x,y = val_split(x,y, params[\"val_size\"])\n",
    "\n",
    "# for method in m:\n",
    "config_desktop()\n",
    "\n",
    "model = make_model(x, y, params)\n",
    "\n",
    "weights = determen_weights(y)\n",
    "H, score, model = train_model(model,x,y,x_val,y_val,x_test,y_test, params[\"epochs\"], params[\"Batch_size\"])\n",
    "predictions = get_feature_vector(model, x, layer = 'fc2')\n",
    "predictions_test = get_feature_vector(model, x_test, layer = 'fc2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = predictions/predictions.max()\n",
    "X = predictions_test/predictions_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "score = auc_svm(x,y,X,y_test, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6321097602735108"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
